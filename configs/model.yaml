# Model Configuration
model_type: "xgboost" # options: logistic_regression, random_forest, xgboost, lightgbm, catboost, mlp, lstm

# Hyperparameters for each model type
params:
  xgboost:
    n_estimators: 100
    max_depth: 5
    learning_rate: 0.1
    objective: "multi:softmax"
    num_class: 3
    n_jobs: -1
    random_state: 42

  random_forest:
    n_estimators: 100
    max_depth: 10
    n_jobs: -1
    random_state: 42

  logistic_regression:
    C: 1.0
    solver: "lbfgs"
    multi_class: "multinomial"
    max_iter: 1000
    n_jobs: -1

  mlp:
    hidden_layers: [64, 32]
    activation: "relu"
    dropout: 0.2
    epochs: 20
    batch_size: 32
    learning_rate: 0.001

  lstm:
    hidden_dim: 64
    num_layers: 2
    dropout: 0.2
    seq_length: 10 # Lookback window
    epochs: 20
    batch_size: 32
    learning_rate: 0.001
